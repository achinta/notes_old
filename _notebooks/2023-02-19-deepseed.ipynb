{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is notes from the [ZeRO - Memory Optimization](https://arxiv.org/abs/1910.02054) paper\n",
    "\n",
    "Data Parallelism (DP) and Model Parallelism (MP) are two ways to parallelize training. \n",
    "\n",
    "**Data Parallelism** we split the data across multiple GPUS and each GPU contains a copy of the model. The gradients are averaged across the GPUs and then applied to the model in each optimizer step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
